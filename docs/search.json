[
  {
    "objectID": "posts/Thomas_fire/index.html",
    "href": "posts/Thomas_fire/index.html",
    "title": "Impacts of the Thomas Fire",
    "section": "",
    "text": "The 2017 Thomas Fire in Santa Barbara and Ventura County, was one of the largest fires in California’s history with over 280,000 acres burned. By looking at the Air Quality Index (AQI) and fire scars resulting from the fire, we can begin to visualize its devastating effects.\nView more information and additional data exploration located on my Github. View the full repository here\n\nCredit to Ray Ford/ Noozhawk\n\n\nThe purpose of this project is to analyze both AQI and Landsat data from the Santa Barbara County area to explore the fire’s effects.\nFirst, we look at AQI data from 2017 and 2018, subsetting specifically for Santa Barbara County, and creating a rolling mean, which allows us to create a graph visualizing the spike is Air Quality Index at the time of the fire.\nSecond, we explore Landsat data, using both true and false color imagery to show the benefits of using false color imagery. We used the Landsat data, combined with the Thomas Fire data to map the effects of the fire.\nHighlights include\n\ndate and string data wrangling\nvisualizing time series\nuse of the .rolling function to find averages\nuse of .loc for spatial subsetting\nuse of .squeeze and .drop_vars to remove bands\nload and explore data with rioxr.open_rasterio()\nclip one dataset to another using .rio.clip_box\ncreation of true and false imagery\ncrs transformation\n\n\n\n\nThe AQI data is updated twice a year by the Environmental Protection Agency (EPA). It contains Air Quality Index data by day, year, and county. It is from a collection of pregenerated data from outdoor monitors across the US. The data was retrieved from the EPA website\nThe Landsat data is a simplified collection of bands (red, green, blue, near-infrared and shortwave infrared) from the Landsat Collection 2 Level-2 atmosperically corrected surface reflectance data, collected by the Landsat 8 satellite. The data was retrieved from the Microsoft Planetary Computer Data Catalogue and pre-processed to remove data outside land and coarsen the spatial resolution.\nThe Thomas fire data is a subset of the shapefile from California Fires (all) from Data.gov, which contains fire data for all of California. This data is updated annualy by The California Department of Forestry and Fire Protection’s Fire and Resource Assessment Program.\n\n\n\nAir Quality Index is determined by the concentrations of pollutants in the air, and has a range of values that determine health\n\nGood (green): 0 to 50\nModerate (yellow): 51 to 100\nUnhealthy for sensitive groups (orange): 101 to 150\nUnhealthy (red): 151 to 200\nVery unhealthy (purple): 201 to 300\nHazardous (maroon): 300 +\n\nBy plotting the AQI of before, during, and after the Thomas Fire, we can view one of the fire’s important effects on people and the environment.\n\n\nLoad in the necessary packages to run our analysis\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport rioxarray as rioxr\nimport matplotlib.patches as mpatches\n\nRead in data for the Air Quality Index in 2017 and 2018 using pandas to create pandas.DataFrames\n\naqi_17 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip\", compression = 'zip')\naqi_18 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip\", compression = 'zip')\n\nWe currently have two separate data frames for two separate years. Combining them using the .concat pandas function allows us to “glue” the data together into one pandas.DataFrame\n\n# Concatenate the two datasets to combine\naqi = pd.concat([aqi_17, aqi_18])\n\n\n\n\nChange column names to lower case and replace spaces with underscores for continuity and easier wrangling\n\n# Clean column names\naqi.columns = aqi.columns.str.lower().str.replace(' ','_')\n\n# Print column names to confirm lower snake case change\nprint(aqi.columns)\n\nIndex(['state_name', 'county_name', 'state_code', 'county_code', 'date', 'aqi',\n       'category', 'defining_parameter', 'defining_site',\n       'number_of_sites_reporting'],\n      dtype='object')\n\n\nTo effectively work with time series data, we need to make sure that the date column is set as a pd.datetime object. This ensures that python realizes that the date column corresponds to dates. We will then set the date column as the index to work with the time series data and easily plot it later on.\n\n# Change date column to datetime object\naqi.date = pd.to_datetime(aqi['date'])\n\n\n# Set date as index\naqi = aqi.set_index('date')\n\n\n\n\nWe actually only want to use a portion of the aqi dataset. We will subset the data for only Santa Barbara County because we are interested only in the effects of the Thomas Fire, which occured in that county.\n\n# Subset county_name\naqi_sb = aqi[aqi['county_name'] == 'Santa Barbara']\n\nCalculate the five day average of the AQI. We will do this using the .rolling() function, a lazy function that will allow us to calculate the mean over the given window. In this case we want to see the five day average. We will create a new column called five_day_average to keep this information in our dataframe.\n\naqi_sb.loc[:, 'five_day_average'] = aqi_sb['aqi'].rolling(window='5D').mean()\n\n\n\n\nWe will use .plot() to visualize the five day average and the daily AQI surrounding and during the Thomas Fire.\n\n\nfig, ax = plt.subplots()\nax.set_title(\"Air Quality Index of Thomas Fire and Surrounding Years\", \n             fontsize=12, loc='center', pad=10)\naqi_sb['aqi'].plot(ax=ax, \n                color='orange')\naqi_sb['five_day_average'].plot(ax=ax, \n                color='blue',\n                alpha=0.7)\n# Add a custom legend element manually\ncustom_patch = mpatches.Patch(color='orange', label='Daily AQI')\n\ncustom_patch_average = mpatches.Patch(color = 'blue', label = 'Five Day AQI Average')\n# Add custom legend\nax.legend(handles=[custom_patch, custom_patch_average], loc='lower left', fontsize=8, frameon=True, bbox_to_anchor=(0.65, .8))\nplt.show()\n\n\n\n\n\n\n\n\nThe Thomas Fire burned in December 2017 through January 2018. When looking at that time frame on our plot, we can clearly see how the fire significantly drove up the AQI. This makes sense, as a large fire releases many contaminants into the air, driving up the index. Recalling back to the AQI index number indications, we can see that the five day average during the fire got above 200, which is very unhealthy. It even appears that the daily AQI reached over 300, putting it into the highest and most hazardous category.\n\n\n\n\nThe Landsat satellite has the ability to capture a collection of bands (red, green, blue, near-infrared and shortwave infrared) through data on reflected light. The appearance of each of these bands indicates the presence of different materials in the environment. Using false color imagery can help us visualize bands we cannot see with our naked eye, and better understand what they mean.\n\nCredit to NASA, ESA, Leah Hustak (STScI)\n\n\nWe will be using our Landsat data to analyze fire scars from the Thomas Fire. In order to visualize these scars, it’s helpful to have a boundary of the fire. Let’s add in our fire data and filter it down to the 2017 Thomas Fire to use in our map later on.\n\n# Read in fire data\npath = fp = os.path.join(\"data\",\"California_Fire_Perimeters_(all).shp\") \n\nperimeters = gpd.read_file(path) \n\n\n\n\nLet’s do some exploration into our data. It’s always important to look at the CRS, ellipsoid, datum, and projection when we are going to combine multiple datasets. We want to make sure that all of our information is consistent before we combine them. Remember that we will combine this with our Landsat data later on.\n\n# Explore CRS\nprint(f\"ellipsoid: {perimeters.crs.ellipsoid}\")\nprint(f\"datum: {perimeters.crs.datum}\")\nprint(f\"crs: {perimeters.crs}\")\nprint(f\"{'Is the CRS geographic?:':&lt;25} {perimeters.crs.is_geographic}\")\nprint(f\"{'Is the CRS projected?:':&lt;25} {perimeters.crs.is_projected}\")\n\nellipsoid: WGS 84\ndatum: World Geodetic System 1984 ensemble\ncrs: EPSG:3857\nIs the CRS geographic?:   False\nIs the CRS projected?:    True\n\n\n\n\n\nWe don’t want fire data for the entire state, so let’s select only for the Thomas Fire in 2017. We will use our filtered down fire data in our map alongside our Landsat data to visualize the Thomas Fire area.\n\n# Select for only the Thomas Fire 2017\nthomas_fire = perimeters.loc[(perimeters['FIRE_NAME'] == \"THOMAS\") &\n                                 (perimeters['YEAR_'] == 2017)]\n\n\n\n\n\n# Load in Landsat data \nroot = os.path.join('/',\n                  'courses',\n                  'EDS220',\n                  'data',\n                  'hwk4_landsat_data')\n\nfp = os.path.join(root,\n                 'landsat8-2018-01-26-sb-simplified.nc')\n\nlandsat = rioxr.open_rasterio(fp)\n\n# View Landsat \nlandsat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 25MB\nDimensions:      (band: 1, x: 870, y: 731)\nCoordinates:\n  * band         (band) int64 8B 1\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\nData variables:\n    red          (band, y, x) float64 5MB ...\n    green        (band, y, x) float64 5MB ...\n    blue         (band, y, x) float64 5MB ...\n    nir08        (band, y, x) float64 5MB ...\n    swir22       (band, y, x) float64 5MB ...xarray.DatasetDimensions:band: 1x: 870y: 731Coordinates: (4)band(band)int641array([1])x(x)float641.213e+05 1.216e+05 ... 3.559e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., ..., 355395., 355665., 355935.])y(y)float643.952e+06 3.952e+06 ... 3.755e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., ..., 3755835., 3755565., 3755295.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)Data variables: (5)red(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]green(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]blue(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]nir08(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]swir22(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0, 122115.0, 122385.0, 122655.0, 122925.0,\n       123195.0, 123465.0, 123735.0,\n       ...\n       353505.0, 353775.0, 354045.0, 354315.0, 354585.0, 354855.0, 355125.0,\n       355395.0, 355665.0, 355935.0],\n      dtype='float64', name='x', length=870))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0, 3951585.0, 3951315.0, 3951045.0,\n       3950775.0, 3950505.0, 3950235.0, 3949965.0,\n       ...\n       3757725.0, 3757455.0, 3757185.0, 3756915.0, 3756645.0, 3756375.0,\n       3756105.0, 3755835.0, 3755565.0, 3755295.0],\n      dtype='float64', name='y', length=731))Attributes: (0)\n\n\nBecause this data is an xarray.Dataset, we can simply call landsat to see information about it. Its dimensions are x:870, y:731, with one band. The data variables are red, green, blue, nir08, swir22. We can see that there is only one band, so we can get rid of the band dimension\n\n# Drop band dimensions and remove coordinates associated to band\nlandsat = landsat.squeeze()\nlandsat = landsat.drop_vars('band')\n# Print to confirm results\nprint(landsat.dims, landsat.coords)\n\nFrozenMappingWarningOnValuesAccess({'x': 870, 'y': 731}) Coordinates:\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\n\n\n\n\n\nUsing our Landsat data, we can now begin to look at fire scars from the 2017 Thomas Fire. First we will create a true color image, meaning that we will plot the landsat data in the correct colors that we would see in a normal image. The red = red, green = green, and blue = blue. This will help us get an idea of the map that we are working with and see how clear it is to see the fire scars normally.\nIndex the colors in order to create a true color image\n\n# Add robust = True to view true color RGB image\nlandsat[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow(robust = True)\n\n\n\n\n\n\n\n\nWith the true color image, our entire plot looks very monochromatic. It’s not possible to see the effects of the Thomas Fire, as all of the land looks extremely similar. In order to get any information from our plot, we need to switch our image to false color.\n\n\n\n\nOur false color image will plot the short-wave infrared (swir22), near-infrared, and red variables (in that order).\n\n# Plot false color image\nlandsat[[\"swir22\", \"nir08\", \"red\"]].to_array().plot.imshow(robust = True)\n\n\n\n\n\n\n\n\n\n\n\nWe will create a map showing the shortwave infrared/near-infrared/red false color image together with the Thomas Fire. This will allow us to understand what fire scars we are seeing in the environment.\nWhenever we combine spatial data we have to check that the CRSs match, and reproject if they do not.\n\n# Examine CRss\nprint('thomas_fire CRS: ', thomas_fire.crs)\nprint('landsat CRS: ', landsat.rio.crs)\n\nthomas_fire CRS:  EPSG:3857\nlandsat CRS:  EPSG:32611\n\n\n\n# Reproject thomas_fire to landsat crs\nthomas_fire = thomas_fire.to_crs(landsat.rio.crs)\n\nIn addition to layering the perimeter data on top of the Landsat data, we also want to “zoom in” on the area we are interested in. We will clip the Landsat data to the Thomas fire bounds using .rio.clip_box()\n\n# Clip data\nlandsat_small = landsat.rio.clip_box(*thomas_fire.total_bounds)\n\nLet’s finally create a clean plot of our false color image.\n\n# Set aspect ratio\nlandsat_aspect_ratio = landsat.rio.width / landsat.rio.height\n\n# Plot clipped data\nfig, ax = plt.subplots(figsize=(6, 6 * landsat_aspect_ratio))  \nlandsat_small[[\"swir22\", \"nir08\", \"red\"]].to_array().plot.imshow(robust = True, ax=ax)\nthomas_fire.boundary.plot(ax=ax, linewidth=1, edgecolor='black', label = \"Thomas Fire Perimeter\")\n\nax.set_axis_off()\nax.set_title('False Color Imagery Map of the 2017\\nThomas Fire in Ventura and Santa Barbara County')\nfig.text(0.5, 0.27, 'Data Source: CAL FIRE via Data.gov & Microsoft Planetary Computer Data Catalogue', ha='center', va='center', fontsize=8, color='black', fontstyle='italic') \nfig.text(0.5, 0.25, 'Date Accessed: 11/22/24', ha='center', va='center', fontsize=8, color='black', fontstyle='italic')\nax.legend(loc='upper right')\nfig.savefig('landsat_map_thomas_fire.png', dpi=300, bbox_inches='tight')\nplt.show()\n\n\n\n\n\n\n\n\nFalse color imagery is being used to show the scar from the 2017 Thomas Fire. We can see that the color is significantly different inside the Thomas Fire Perimeter. The difference in color indicates a difference in vegetation (ie. dead vs alive) which more easily shows us the effects of the Thomas Fire than a true color image would.\nLet’s break down the false color image|\nThe red represents shortwave infrared wavelengths which is shown on the far right side of the figure, after the 2,000 nanometer mark. We can see that the shortwave infrared shows mostly dry soil. That means that where we are seeing red on our map, that is dry soil, meaning a lack of living vegetation.\nThe green represents near-infrared wavelengths, which is shown on the figure between wavelengths of 850 t0 880. We can see that the near-infrared wavelengths show mostly healthy vegetation. That means that where we are seeing green on our map, that is vegetation, meaning a lack of fire scars.\nThe blue represents red. We don’t see any blue in our image, so we do not need to worry about its reflectance.\n\n\nMicrosoft Planetary Computer Data Catalogue, Landsat collection 2 Level-2. Available from: https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2. Access date: December 3rd, 2024.\nData.gov Data Catalogue, California Fire Perimeters (all). Available from: https://catalog.data.gov/dataset/california-fire-perimeters-all-b3436. Access date: December 3rd, 2024.\nAirData, US EPA. Available from: https://aqs.epa.gov/aqsweb/airdata/download_files.html. Access date: December 3rd, 2024"
  },
  {
    "objectID": "posts/Thomas_fire/index.html#air-quality-index-during-thomas-fire",
    "href": "posts/Thomas_fire/index.html#air-quality-index-during-thomas-fire",
    "title": "Impacts of the Thomas Fire",
    "section": "",
    "text": "Air Quality Index is determined by the concentrations of pollutants in the air, and has a range of values that determine health\n\nGood (green): 0 to 50\nModerate (yellow): 51 to 100\nUnhealthy for sensitive groups (orange): 101 to 150\nUnhealthy (red): 151 to 200\nVery unhealthy (purple): 201 to 300\nHazardous (maroon): 300 +\n\nBy plotting the AQI of before, during, and after the Thomas Fire, we can view one of the fire’s important effects on people and the environment.\n\n\nLoad in the necessary packages to run our analysis\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport rioxarray as rioxr\nimport matplotlib.patches as mpatches\n\nRead in data for the Air Quality Index in 2017 and 2018 using pandas to create pandas.DataFrames\n\naqi_17 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip\", compression = 'zip')\naqi_18 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip\", compression = 'zip')\n\nWe currently have two separate data frames for two separate years. Combining them using the .concat pandas function allows us to “glue” the data together into one pandas.DataFrame\n\n# Concatenate the two datasets to combine\naqi = pd.concat([aqi_17, aqi_18])\n\n\n\n\nChange column names to lower case and replace spaces with underscores for continuity and easier wrangling\n\n# Clean column names\naqi.columns = aqi.columns.str.lower().str.replace(' ','_')\n\n# Print column names to confirm lower snake case change\nprint(aqi.columns)\n\nIndex(['state_name', 'county_name', 'state_code', 'county_code', 'date', 'aqi',\n       'category', 'defining_parameter', 'defining_site',\n       'number_of_sites_reporting'],\n      dtype='object')\n\n\nTo effectively work with time series data, we need to make sure that the date column is set as a pd.datetime object. This ensures that python realizes that the date column corresponds to dates. We will then set the date column as the index to work with the time series data and easily plot it later on.\n\n# Change date column to datetime object\naqi.date = pd.to_datetime(aqi['date'])\n\n\n# Set date as index\naqi = aqi.set_index('date')\n\n\n\n\nWe actually only want to use a portion of the aqi dataset. We will subset the data for only Santa Barbara County because we are interested only in the effects of the Thomas Fire, which occured in that county.\n\n# Subset county_name\naqi_sb = aqi[aqi['county_name'] == 'Santa Barbara']\n\nCalculate the five day average of the AQI. We will do this using the .rolling() function, a lazy function that will allow us to calculate the mean over the given window. In this case we want to see the five day average. We will create a new column called five_day_average to keep this information in our dataframe.\n\naqi_sb.loc[:, 'five_day_average'] = aqi_sb['aqi'].rolling(window='5D').mean()\n\n\n\n\nWe will use .plot() to visualize the five day average and the daily AQI surrounding and during the Thomas Fire.\n\n\nfig, ax = plt.subplots()\nax.set_title(\"Air Quality Index of Thomas Fire and Surrounding Years\", \n             fontsize=12, loc='center', pad=10)\naqi_sb['aqi'].plot(ax=ax, \n                color='orange')\naqi_sb['five_day_average'].plot(ax=ax, \n                color='blue',\n                alpha=0.7)\n# Add a custom legend element manually\ncustom_patch = mpatches.Patch(color='orange', label='Daily AQI')\n\ncustom_patch_average = mpatches.Patch(color = 'blue', label = 'Five Day AQI Average')\n# Add custom legend\nax.legend(handles=[custom_patch, custom_patch_average], loc='lower left', fontsize=8, frameon=True, bbox_to_anchor=(0.65, .8))\nplt.show()\n\n\n\n\n\n\n\n\nThe Thomas Fire burned in December 2017 through January 2018. When looking at that time frame on our plot, we can clearly see how the fire significantly drove up the AQI. This makes sense, as a large fire releases many contaminants into the air, driving up the index. Recalling back to the AQI index number indications, we can see that the five day average during the fire got above 200, which is very unhealthy. It even appears that the daily AQI reached over 300, putting it into the highest and most hazardous category."
  },
  {
    "objectID": "posts/Thomas_fire/index.html#landsat-data-of-thomas-fire",
    "href": "posts/Thomas_fire/index.html#landsat-data-of-thomas-fire",
    "title": "Impacts of the Thomas Fire",
    "section": "",
    "text": "The Landsat satellite has the ability to capture a collection of bands (red, green, blue, near-infrared and shortwave infrared) through data on reflected light. The appearance of each of these bands indicates the presence of different materials in the environment. Using false color imagery can help us visualize bands we cannot see with our naked eye, and better understand what they mean.\n\nCredit to NASA, ESA, Leah Hustak (STScI)\n\n\nWe will be using our Landsat data to analyze fire scars from the Thomas Fire. In order to visualize these scars, it’s helpful to have a boundary of the fire. Let’s add in our fire data and filter it down to the 2017 Thomas Fire to use in our map later on.\n\n# Read in fire data\npath = fp = os.path.join(\"data\",\"California_Fire_Perimeters_(all).shp\") \n\nperimeters = gpd.read_file(path) \n\n\n\n\nLet’s do some exploration into our data. It’s always important to look at the CRS, ellipsoid, datum, and projection when we are going to combine multiple datasets. We want to make sure that all of our information is consistent before we combine them. Remember that we will combine this with our Landsat data later on.\n\n# Explore CRS\nprint(f\"ellipsoid: {perimeters.crs.ellipsoid}\")\nprint(f\"datum: {perimeters.crs.datum}\")\nprint(f\"crs: {perimeters.crs}\")\nprint(f\"{'Is the CRS geographic?:':&lt;25} {perimeters.crs.is_geographic}\")\nprint(f\"{'Is the CRS projected?:':&lt;25} {perimeters.crs.is_projected}\")\n\nellipsoid: WGS 84\ndatum: World Geodetic System 1984 ensemble\ncrs: EPSG:3857\nIs the CRS geographic?:   False\nIs the CRS projected?:    True\n\n\n\n\n\nWe don’t want fire data for the entire state, so let’s select only for the Thomas Fire in 2017. We will use our filtered down fire data in our map alongside our Landsat data to visualize the Thomas Fire area.\n\n# Select for only the Thomas Fire 2017\nthomas_fire = perimeters.loc[(perimeters['FIRE_NAME'] == \"THOMAS\") &\n                                 (perimeters['YEAR_'] == 2017)]\n\n\n\n\n\n# Load in Landsat data \nroot = os.path.join('/',\n                  'courses',\n                  'EDS220',\n                  'data',\n                  'hwk4_landsat_data')\n\nfp = os.path.join(root,\n                 'landsat8-2018-01-26-sb-simplified.nc')\n\nlandsat = rioxr.open_rasterio(fp)\n\n# View Landsat \nlandsat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 25MB\nDimensions:      (band: 1, x: 870, y: 731)\nCoordinates:\n  * band         (band) int64 8B 1\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\nData variables:\n    red          (band, y, x) float64 5MB ...\n    green        (band, y, x) float64 5MB ...\n    blue         (band, y, x) float64 5MB ...\n    nir08        (band, y, x) float64 5MB ...\n    swir22       (band, y, x) float64 5MB ...xarray.DatasetDimensions:band: 1x: 870y: 731Coordinates: (4)band(band)int641array([1])x(x)float641.213e+05 1.216e+05 ... 3.559e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., ..., 355395., 355665., 355935.])y(y)float643.952e+06 3.952e+06 ... 3.755e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., ..., 3755835., 3755565., 3755295.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)Data variables: (5)red(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]green(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]blue(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]nir08(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]swir22(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0, 122115.0, 122385.0, 122655.0, 122925.0,\n       123195.0, 123465.0, 123735.0,\n       ...\n       353505.0, 353775.0, 354045.0, 354315.0, 354585.0, 354855.0, 355125.0,\n       355395.0, 355665.0, 355935.0],\n      dtype='float64', name='x', length=870))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0, 3951585.0, 3951315.0, 3951045.0,\n       3950775.0, 3950505.0, 3950235.0, 3949965.0,\n       ...\n       3757725.0, 3757455.0, 3757185.0, 3756915.0, 3756645.0, 3756375.0,\n       3756105.0, 3755835.0, 3755565.0, 3755295.0],\n      dtype='float64', name='y', length=731))Attributes: (0)\n\n\nBecause this data is an xarray.Dataset, we can simply call landsat to see information about it. Its dimensions are x:870, y:731, with one band. The data variables are red, green, blue, nir08, swir22. We can see that there is only one band, so we can get rid of the band dimension\n\n# Drop band dimensions and remove coordinates associated to band\nlandsat = landsat.squeeze()\nlandsat = landsat.drop_vars('band')\n# Print to confirm results\nprint(landsat.dims, landsat.coords)\n\nFrozenMappingWarningOnValuesAccess({'x': 870, 'y': 731}) Coordinates:\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\n\n\n\n\n\nUsing our Landsat data, we can now begin to look at fire scars from the 2017 Thomas Fire. First we will create a true color image, meaning that we will plot the landsat data in the correct colors that we would see in a normal image. The red = red, green = green, and blue = blue. This will help us get an idea of the map that we are working with and see how clear it is to see the fire scars normally.\nIndex the colors in order to create a true color image\n\n# Add robust = True to view true color RGB image\nlandsat[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow(robust = True)\n\n\n\n\n\n\n\n\nWith the true color image, our entire plot looks very monochromatic. It’s not possible to see the effects of the Thomas Fire, as all of the land looks extremely similar. In order to get any information from our plot, we need to switch our image to false color."
  },
  {
    "objectID": "posts/Thomas_fire/index.html#false-color-image",
    "href": "posts/Thomas_fire/index.html#false-color-image",
    "title": "Impacts of the Thomas Fire",
    "section": "",
    "text": "Our false color image will plot the short-wave infrared (swir22), near-infrared, and red variables (in that order).\n\n# Plot false color image\nlandsat[[\"swir22\", \"nir08\", \"red\"]].to_array().plot.imshow(robust = True)"
  },
  {
    "objectID": "posts/Thomas_fire/index.html#map-our-false-color-imagery",
    "href": "posts/Thomas_fire/index.html#map-our-false-color-imagery",
    "title": "Impacts of the Thomas Fire",
    "section": "",
    "text": "We will create a map showing the shortwave infrared/near-infrared/red false color image together with the Thomas Fire. This will allow us to understand what fire scars we are seeing in the environment.\nWhenever we combine spatial data we have to check that the CRSs match, and reproject if they do not.\n\n# Examine CRss\nprint('thomas_fire CRS: ', thomas_fire.crs)\nprint('landsat CRS: ', landsat.rio.crs)\n\nthomas_fire CRS:  EPSG:3857\nlandsat CRS:  EPSG:32611\n\n\n\n# Reproject thomas_fire to landsat crs\nthomas_fire = thomas_fire.to_crs(landsat.rio.crs)\n\nIn addition to layering the perimeter data on top of the Landsat data, we also want to “zoom in” on the area we are interested in. We will clip the Landsat data to the Thomas fire bounds using .rio.clip_box()\n\n# Clip data\nlandsat_small = landsat.rio.clip_box(*thomas_fire.total_bounds)\n\nLet’s finally create a clean plot of our false color image.\n\n# Set aspect ratio\nlandsat_aspect_ratio = landsat.rio.width / landsat.rio.height\n\n# Plot clipped data\nfig, ax = plt.subplots(figsize=(6, 6 * landsat_aspect_ratio))  \nlandsat_small[[\"swir22\", \"nir08\", \"red\"]].to_array().plot.imshow(robust = True, ax=ax)\nthomas_fire.boundary.plot(ax=ax, linewidth=1, edgecolor='black', label = \"Thomas Fire Perimeter\")\n\nax.set_axis_off()\nax.set_title('False Color Imagery Map of the 2017\\nThomas Fire in Ventura and Santa Barbara County')\nfig.text(0.5, 0.27, 'Data Source: CAL FIRE via Data.gov & Microsoft Planetary Computer Data Catalogue', ha='center', va='center', fontsize=8, color='black', fontstyle='italic') \nfig.text(0.5, 0.25, 'Date Accessed: 11/22/24', ha='center', va='center', fontsize=8, color='black', fontstyle='italic')\nax.legend(loc='upper right')\nfig.savefig('landsat_map_thomas_fire.png', dpi=300, bbox_inches='tight')\nplt.show()\n\n\n\n\n\n\n\n\nFalse color imagery is being used to show the scar from the 2017 Thomas Fire. We can see that the color is significantly different inside the Thomas Fire Perimeter. The difference in color indicates a difference in vegetation (ie. dead vs alive) which more easily shows us the effects of the Thomas Fire than a true color image would.\nLet’s break down the false color image|\nThe red represents shortwave infrared wavelengths which is shown on the far right side of the figure, after the 2,000 nanometer mark. We can see that the shortwave infrared shows mostly dry soil. That means that where we are seeing red on our map, that is dry soil, meaning a lack of living vegetation.\nThe green represents near-infrared wavelengths, which is shown on the figure between wavelengths of 850 t0 880. We can see that the near-infrared wavelengths show mostly healthy vegetation. That means that where we are seeing green on our map, that is vegetation, meaning a lack of fire scars.\nThe blue represents red. We don’t see any blue in our image, so we do not need to worry about its reflectance.\n\n\nMicrosoft Planetary Computer Data Catalogue, Landsat collection 2 Level-2. Available from: https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2. Access date: December 3rd, 2024.\nData.gov Data Catalogue, California Fire Perimeters (all). Available from: https://catalog.data.gov/dataset/california-fire-perimeters-all-b3436. Access date: December 3rd, 2024.\nAirData, US EPA. Available from: https://aqs.epa.gov/aqsweb/airdata/download_files.html. Access date: December 3rd, 2024"
  },
  {
    "objectID": "posts/fish_infographic/index.html",
    "href": "posts/fish_infographic/index.html",
    "title": "How Fish and Other Marine Species Change Throughout the San Francisco Estuary",
    "section": "",
    "text": "San Francisco is a place I’ve been to many times, but never thought in-depth about the environment and ecosystem there. When I saw the dataset about fish in the estuary, I chose it simply because the data seemed clean and easy to wrangle. It wasn’t until I began designing the infographic that I became very intrigued by the information I could display. I learned about the intentionality of the sample sites, and the meaning behind the abiotic features and fish species caught at each location.\nMy data comes from “Interagency Ecological Program: Over four decades of juvenile fish monitoring data from the San Francisco Estuary, collected by the Delta Juvenile Fish Monitoring Program, 1976-2024”, which is the result of a program from the United States Fish and Wildlife Service. The data, as well as the metadata, can be found at this link https://portal.edirepository.org/nis/mapbrowse?scope=edi&identifier=244\nThe question that my infographic is answering is How do fish and other marine species catches differ between sites in the San Francisco Estuary? I created three sub-questions, one for each plot. The first question is What are the top three most caught marine organisms at each site?, and I answered this question with a bar chart which I made look like fish. The second question is How many unique marine organisms were sampled at each site?, which I answered with a bar chart that I made into the shape of waves. The third question is What is the average water temperature differences between each site?, which I answered with a scatter plot with the color of the points representing the average temperature.\nHere is how my infographic turned out!\n\nI always love making data visualizations as fun as possible. Data can often feel very serious and dry, and I like to challenge myself to change that narrative, hence my colorful and playful themes I went with in this graphic. Here are some elements that I thought about in my infographic:\n\nGraphic Form\n\nI chose some very basic types of plots for my infographic. I only used a scatter plot and bar charts. I liked that these are extremely easy to read and interpret, but also have a lot of potential for customization.\n\nText\n\nI chose to remove the axis labels from my plots, because I felt that the simplicity of the plots made them legible even without axis labels. I did add titles to every plot, but the most text this infographic has are annotations. I felt like the annotations was the most important part of the infographic, because it supplied some much needed context to the plots. Without them, the infographic does not tell such a detailed story of the importance of the San Francisco Estuary.\n\nThemes\n\nIn ggplot, I modified the themes of all of the plots. I changed the width of my bar charts, the colors, the sizes of my points, and the shape of my points. I then transferred all of my work to affinity, where I added some major design elements like making one chart into the shape of waves and another into the shape of fish.\n\nColors\n\nI wanted my infographic to have playful and fun vibes, while still having colors that made sense. All of my palettes are colorblind friendly, and make sense for what they’re visualizing. The wave chart is blue, and the thermometers have a blue to red palette. I had more fun with the colors of the fish, making them colorful and fun.\n\nTypography\n\nI had so much fun with finding cool water and fish themed fonts online. I tested out a bunch of them, and decided that the font Wavepool and MV Boli matched my playful theme I was going for the most. I wanted it to look handwritten, while also staying very legible.\n\nGeneral Design\n\nBecause my plots were pretty minimal, I went a little crazier with the annotations. I used font thickness, size, color, and boxes around text to draw the eye to different elements. There is a lot of information, but I liked the vibe of that, and it was an intentional decision. Without the text that it has, the story of the infographic is very different and less meaningful.\n\nContextualizing My Data\n\nIn boxes in bigger font I gave an overview of the estuary as a whole, and then gave context about individual sites and pointed to their locations through smaller unframed annotations. By doing this, I fit in a lot of information about the estuary and still managed to keep it aesthetically pleasing.\n\nCentering My Primary Message\n\nThe primary message was to think about the ecosystem and environment of the estuary. I wanted to show the problems in the estuary such as invasive species, and also the reliance that humans and animals have on the estuary. I put this information in boxes and annotations around the graphic.\n\nConsidering Accessibility (e.g. colorblind-friendly palettes / contrast, alt text)\n\nI considered accessibility be making the palette colorblind friendly and adding alt text in the code to make it accesible to visually impaired users.\n\nApplying a DEI lens to my design, as appropriate (e.g. considering the people / communities / places represented in your data, consider how you frame your questions / issue)\n\nI thought about people that live and have lived in the area and how they are and were effected. This was something I made sure to mention, as even an infographic more about ecology, still affects people and communities.\nIf you’re interested in the code behind this infographic, take a look below\n\n\nCode\n\n# load libraries\nlibrary(tidyverse)\nlibrary(here)\nlibrary(janitor)\nlibrary(ggtext)\nlibrary(showtext)\n\n# add font awesome fonts\nfont_add('fa-reg', 'fonts/Font Awesome 6 Free-Regular-400.otf')\nfont_add('fa-brands', 'fonts/Font Awesome 6 Brands-Regular-400.otf')\nfont_add('fa-solid', 'fonts/Font Awesome 6 Free-Solid-900.otf')\n\nfont_add_google(name = \"Flavors\", family = \"flavors\")\nfont_add_google(name = \"Outfit\", family = \"outfit\")\n\nshowtext_auto()\n\n# load data\nfish_02_24 &lt;- read_csv(here(\"posts\", \"fish_infographic\", \"data\", \"2002-2024_DJFMP_trawl_fish_and_water_quality_data.csv\"))\nlocals &lt;- read_csv(here(\"posts\", \"fish_infographic\", \"data\", \"DJFMP_Site_Locations.csv\"))\n\n# clean data\nfish_clean &lt;- fish_02_24 |&gt; \n  clean_names() |&gt; \n  select_if(~ sum(is.na(.)) &lt; 750000)\n\n# find unique common names by location\nfish_unique &lt;- fish_clean |&gt; \n  select(location, common_name, sample_date) |&gt; \n  group_by(location) |&gt; \n  summarize(nunique = n_distinct(common_name)) \n\n# plot amount of unique species per location\nunique_plot &lt;- ggplot(data = fish_unique, aes(x = location, y = nunique)) +\n  geom_col(color = \"blue3\", fill = \"navy\", width = 1) +\n  geom_text(aes(label = nunique, \n                vjust = 4), \n            color = \"white\", \n            size = 5,\n            family = \"outfit\") +\n  theme_bw() +\n  scale_x_discrete(expand = c(0, NA)) +\n  scale_y_continuous(expand = c(0, NA), limits = c(0, 80)) +\n  labs(\n    title = \"Number of Unique Species Caught at Each Location\"\n  ) +\n  theme(\n    axis.title.x = element_blank(),\n    axis.title.y = element_blank(),\n    # I anticipate changing the style of the title in affinity so I'll leave it for now\n    title = element_text(family = \"outfit\"),\n    axis.text = element_text(family = \"outfit\",\n                             size = 12),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank(),\n    axis.ticks = element_blank(),\n    axis.text.y = element_blank())\n\n# filter for only the sites in the fish_clean dataset, and select only long and lat\nlocals_sites &lt;- locals |&gt; \n  filter(Location == c(\"Chipps Island\", \"Benicia\", \"Mossdale\", \"Sherwood Harbor\")) |&gt; \n  select(Location, Latitude, Longitude) |&gt; \n  clean_names()\n\n# select only needed columns for question\nfish_abiotic &lt;- fish_clean |&gt; \n  select(location, weather_code, water_temp) |&gt; \n  na.omit(water_temp, weather_code) \n  \n# find average water temp by location\nfish_water &lt;- fish_abiotic |&gt; \n  group_by(location) |&gt; \n  summarize(avg_water_temp = mean(water_temp)) \n\n# find average (mode) weather by location\nfish_weather &lt;- fish_abiotic |&gt; \n  group_by(location) |&gt; \n  summarize(weather = DescTools::Mode(weather_code))\n\n# join all datasets together\nfish_join &lt;- fish_weather |&gt; \n  full_join(fish_water, join_by(location)) \n\nlocal_join &lt;- fish_join |&gt; \n  full_join(locals_sites, join_by(location)) \n\n# plot scatter plot with color as water temperature\ntemp_plot &lt;- ggplot(data = local_join, aes(y = latitude, x = longitude, color = avg_water_temp, label = \"&lt;span style='font-family:fa-solid;'&gt;&#xf2c8;&lt;/span&gt;\")) +\n # geom_point(size = 10) +\n  geom_richtext(size = 60, label.colour = NA, fill = NA) +\n  scale_color_gradient(low = \"navy\",\n                       high = \"red\") +\nlabs(\n  title = \"Temperatures Differ Across Sampling Sites\",\n  subtitle = \"Average temperature changes up to ten degress between sites\",\n  color = \"Avg. Water Temp (°C)\"\n) +\n  theme_bw() +\n  theme(\n    axis.title = element_blank(),\n    axis.text = element_blank(),\n    axis.ticks = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank(),\n    title = element_text(family = \"outfit\",\n                         size = 15),\n    legend.text = element_text(family = \"outfit\"),\n    legend.position = \"left\"\n  ) \n\n# Calculate the catch count for each common_name\nfish_max &lt;- fish_clean |&gt; \n  group_by(location, common_name) |&gt; \n  summarize(max_catch = n(), .groups = \"drop\") \n\n\n# Find the top three highest catches for each location\nfish_top &lt;- fish_max |&gt; \n  filter(common_name != \"No catch\") |&gt; \n  arrange(desc(max_catch)) |&gt; \n  group_by(location) |&gt; \n  slice(1:3) \n\n# plot top three catch types by site\nfish_top_three &lt;- ggplot(data = fish_top, aes(fill = common_name, x = location, y = max_catch)) +\n  geom_bar(position = \"fill\", stat = \"identity\", width = .7) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(fill = \"Common Names\") +\n  # this isn't working with a filled bar chart, I'll just add labels in affinity\n # geom_text(aes(label = max_catch)) +\n  theme(\n    axis.title = element_blank(),\n    axis.text.x = element_blank(),\n    axis.ticks = element_blank(),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    panel.background = element_blank(),\n    legend.text = element_text(family = \"outfit\"),\n    axis.text = element_text(family = \"outfit\")\n  ) +\n  coord_flip()\n\nshowtext_auto(FALSE)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Emma Bea Mitchell",
    "section": "",
    "text": "I’m a recent graduate with a master’s in Environmental Data Science at the Bren School of Environmental Science and Management at UCSB. I graduated from the University of Redlands in 2022, where I majored in Environmental Science, Policy and Justice. I am following my Environmental Justice passion by learning to utilize the power of computer programming to communicate and help repair the harmful impacts of dangerous environmental decisions on people and the environment."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "I’m a recent graduate with a Masters in Environmental Data Science at the Bren School of Environmental Science and Management at UC Santa Barbara. In undergrad, I majored in Environmental Science, Policy, and Justice at the Johnston Center for Integrative Studies at the University of Redlands. I created my personalized major because I loved environmental studies and social activism. I took classes on anything from Environmental Ethics to History of Disability to Biodiversity to Immigration Politics and Policy. I loved having the freedom to choose what I wanted to learn and pursue. In undergrad I also studied abroad in Copenhagen where I had the chance to study ice cores and glacial dating, as well as learn about the geopolitics of Denmark. My passion and excitement about environmental policy and environmental justice drove me to go back to school. I truly believe that data science is needed and connected to all disciplines, and in learning data science skills I hope to begin to do my part to rectify the damage we have done to our Earth and the people living there."
  },
  {
    "objectID": "about.html#who-am-i",
    "href": "about.html#who-am-i",
    "title": "About Me",
    "section": "",
    "text": "I’m a recent graduate with a Masters in Environmental Data Science at the Bren School of Environmental Science and Management at UC Santa Barbara. In undergrad, I majored in Environmental Science, Policy, and Justice at the Johnston Center for Integrative Studies at the University of Redlands. I created my personalized major because I loved environmental studies and social activism. I took classes on anything from Environmental Ethics to History of Disability to Biodiversity to Immigration Politics and Policy. I loved having the freedom to choose what I wanted to learn and pursue. In undergrad I also studied abroad in Copenhagen where I had the chance to study ice cores and glacial dating, as well as learn about the geopolitics of Denmark. My passion and excitement about environmental policy and environmental justice drove me to go back to school. I truly believe that data science is needed and connected to all disciplines, and in learning data science skills I hope to begin to do my part to rectify the damage we have done to our Earth and the people living there."
  },
  {
    "objectID": "about.html#but-who-am-i-really",
    "href": "about.html#but-who-am-i-really",
    "title": "About Me",
    "section": " But who am I really?",
    "text": "But who am I really?\nOutside of my love for the environment and data science, my main hobby is reading (you know you’re a nerd when your two passions are coding and reading 🤓). Apart from staring at a screen or a book, I love to kayak, swim, paddle board, and hike. I am originally from Seattle, WA where I was surrounded by the vast nature of the Cascades, the Olympics, and the Puget Sound. I grew up going to summer camps on islands, raising salmon in school, and cannon-balling off diving boards in my neighborhood lake. In 2024 I moved to Santa Barbara to pursue my Master’s degree, where (thank goodness) I am still surrounded by mountains and ocean and my home is full of books."
  },
  {
    "objectID": "delete-later/practice.html",
    "href": "delete-later/practice.html",
    "title": "Here is my level one header",
    "section": "",
    "text": "Here is my level one header\nHere is my first paragraph\nHere is my second paragraph, where you can read more about MEDS.\nThis is very important text!"
  },
  {
    "objectID": "posts/EJ_LA/index.html",
    "href": "posts/EJ_LA/index.html",
    "title": "Environmental Justice and Biodiversity",
    "section": "",
    "text": "Redlining began during the Great Depression, when FDR introduced the New Deal, a program designed to help Americans suffering financially. Although many of the reforms in the New Deal were successful, others were extremely discriminatory. During this time, the Home Owners Loan Corporation (HOLC) was created. This agency was designed to help with the housing crisis and prevent foreclosures through refinancing. This involved lenders and real estate agents grading the investment risks of neighborhoods. Unfortunately, these grades were heavily based on racial and socioeconomic makeup.\nGrades included:\nLower grades were given to neighborhoods that were majority black, minorities, immigrants, or poor whites. This prevented people of color from moving to majority white neighborhoods and greatly financially impacted homeowners of color. (https://clkrep.lacity.org/onlinedocs/2019/19-0600_misc_5-6-19.pdf)\nAlthough redlining was outlawed in the 1968 Fair Housing Act, many effects of redlining have continued to present day. In this project, I mapped and explored the graded makeup of LA as well as biodiversity in previously redlined districts in present day."
  },
  {
    "objectID": "posts/EJ_LA/index.html#set-up",
    "href": "posts/EJ_LA/index.html#set-up",
    "title": "Environmental Justice and Biodiversity",
    "section": "Set-Up",
    "text": "Set-Up\n\nRead In Libraries and Data\n\n\nCode\n# Load libraries\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(stars)\nlibrary(tmap)\nlibrary(here)\nlibrary(kableExtra)\nlibrary(patchwork)\nlibrary(testthat)\n\n\n\n# Read in data\nejscreen &lt;- sf::st_read(here::here(\"posts\", \"EJ_LA\", \"data\", \"ejscreen\",\"EJSCREEN_2023_BG_StatePct_with_AS_CNMI_GU_VI.gdb\")) \n\nbirds &lt;- sf::st_read(here::here(\"posts\", \"EJ_LA\",\"data\", \"gbif-birds-LA\", \"gbif-birds-LA.shp\"))\n\nholc &lt;- sf::st_read(here::here(\"posts\", \"EJ_LA\",\"data\", \"mapping-inequality\", \"mapping-inequality-los-angeles.json\")) %&gt;%\n  filter(st_is_valid(.))"
  },
  {
    "objectID": "posts/EJ_LA/index.html#data-wrangling",
    "href": "posts/EJ_LA/index.html#data-wrangling",
    "title": "Environmental Justice and Biodiversity",
    "section": "Data Wrangling",
    "text": "Data Wrangling\nIn order to effectively explore the effects of redlining, we need to zoom in on a specific area. Much of our data covers the entire US, so we need to narrow it down to just LA.\n\n# Filter down data to look only at LA County\nCalifornia &lt;- ejscreen |&gt;\n  dplyr::filter(ST_ABBREV == \"CA\" & ID != \"060379903000\" & ID != \"060379902000\")\n\nLA &lt;- California |&gt;\n  dplyr::filter(CNTY_NAME == \"Los Angeles County\") \n\n# Check if the coordinate system is the same\nprint(st_crs(LA) == st_crs(holc))\n\n[1] FALSE\n\n# Transform data to same coordinate system\nholc_transform &lt;- st_transform(holc, crs = st_crs(LA))\n\n# Check that it works\nif(st_crs(holc_transform) == st_crs(LA)){\n  print(\"it's a match!\")\n} else {\n  stop(\"not a match, check your coordinate systems!\")\n}\n\n[1] \"it's a match!\"\n\n\n\n# Make data set for counties surrounding LA for map\nsurrounding_Counties &lt;- California |&gt;\n  dplyr::filter(CNTY_NAME == \"San Bernardino County\" | CNTY_NAME == \"Orange County\" )\n# Transform data to same coordinate system\nsurrounding_transform &lt;- st_transform(surrounding_Counties, crs = st_crs(LA))\n\n# Check our transformation\nif(st_crs(surrounding_transform) == st_crs(LA)){\n  print(\"it's a match!\")\n} else {\n  stop(\"not a match, check your coordinate systems!\")\n}\n\n[1] \"it's a match!\"\n\n# Transform California data to same coordinate system\nCalifornia_transform &lt;- st_transform(California, crs = st_crs(LA))\n\n# Check our transformation\nif(st_crs(California_transform) == st_crs(LA)){\n  print(\"it's a match!\")\n} else {\n  stop(\"not a match, check your coordinate systems!\")\n}\n\n[1] \"it's a match!\""
  },
  {
    "objectID": "posts/EJ_LA/index.html#map-holc-grades-in-la",
    "href": "posts/EJ_LA/index.html#map-holc-grades-in-la",
    "title": "Environmental Justice and Biodiversity",
    "section": "Map HOLC Grades in LA",
    "text": "Map HOLC Grades in LA\n\n\nCode\n# Map HOLC grades \nHOLC_map &lt;- tm_shape(California_transform, bbox = holc_transform) +\n  tm_polygons(col = \"beige\") +\ntm_shape(holc_transform) +\n  tm_fill(\"grade\",\n          palette = c(\"A\" = \"green\",\n                      \"B\" = \"yellow\",\n                      \"C\" = \"orange\",\n                      \"D\" = \"red\"),\n          title = \"HOLC Grades\") +\n  tm_shape(LA, bbox = holc_transform) +\n  tm_borders() +\n  tm_shape(surrounding_Counties) +\n  tm_borders(alpha = .2) +\n  tm_layout(main.title = \"Home Owners' Loan Corporation\\nGrades in LA County\",\n            legend.position = c(\"right\", \"top\"),\n            legend.title.size = .8,\n            legend.height = -.3,\n            main.title.position = \"center\",\n            main.title.size = 1,\n            bg.color = \"skyblue\",\n            outer.bg.color = \"slategrey\",\n            legend.frame = TRUE,\n            legend.frame.lwd = 1.5,\n            legend.bg.color = \"beige\",\n            fontfamily = \"serif\") +\n  tm_compass(position = c(\"left\", \"bottom\"), size = .7, type = 'arrow') +\n  tm_scale_bar(position = c(\"left\", \"bottom\"))\n\n# View map\nHOLC_map\n\n\n\n\n\n\n\n\n\n\n# Join data to summarize census block groups within each HOLC grade\ncensus_percent &lt;- st_join(holc_transform, LA, join = st_intersects) |&gt;\n  group_by(grade) |&gt;\n  summarize(pct_block_groups_in_LA = n()/nrow(LA)*100) |&gt;\n  st_drop_geometry() |&gt;\n  rename(Grade = grade, \"Pct of Block Groups in LA\" = pct_block_groups_in_LA)\n\n\n# view table\nkbl(census_percent, caption = \"Percent of Current Census Block Groups Within Each HOLC Grade\") |&gt;\n  kable_classic(full_width = FALSE, html_font = \"Cambria\")\n\n\nPercent of Current Census Block Groups Within Each HOLC Grade\n \n  \n    Grade \n    Pct of Block Groups in LA \n  \n \n\n  \n    A \n    6.814388 \n  \n  \n    B \n    18.303233 \n  \n  \n    C \n    41.705873 \n  \n  \n    D \n    19.729853 \n  \n  \n    NA \n    4.492336 \n  \n\n\n\n\n\nfor context: the percentages do not add up to 100 percent because we chose not to deal with overlapping census blocks and HOLC grades. With the information and skill set provided at the moment, the percentage error is cautiously overlooked\nMapping HOLC grades in LA greatly helps to visualize the redlining present in the early to mid 1900s. In order to look at one of the many lasting effects of redlining, let’s first look at the connection between the percent of low income population, particulate matter concentrations, and low life expectancy percentiles in each grade.\n\nCurrent Conditions\n\n\nCode\n# Join data sets and drop geometry to get summary stats\nsum_stats &lt;- st_join(holc_transform, LA, join = st_intersects) |&gt;\n  st_drop_geometry() \n\n# Plot box plots with means for low income, PM 2.5, and life exp. \nlow_inc &lt;- ggplot(sum_stats, aes(grade,LOWINCPCT, fill = grade))+\n  geom_boxplot(show.legend = FALSE) +\n  stat_summary(fun =mean, geom =\"point\", shape=20, size=6, color=\"pink\", fill=\"pink\") +\n    theme(legend.position=\"none\") +\n    scale_fill_brewer(palette=\"Set1\") +\n  labs(x = \"HOLC Grades\",\n       y = \"Percent of Low Income Population\",\n       caption = \"     * Mean of each box plot\\n represented by a pink circle\",\n       title = \"Income, Particulate Matter Concentrations,\\nand Life Expectancy Disparities by HOLC Grade\") +\n  theme_minimal()\n\nPM_p &lt;- ggplot(sum_stats, aes(grade,P_PM25, fill = grade))+\n  geom_boxplot(show.legend = FALSE) +\n  stat_summary(fun =mean, geom =\"point\", shape=20, size=6, color=\"pink\", fill=\"pink\") +\n    theme(legend.position=\"none\") +\n    scale_fill_brewer(palette=\"Set1\") +\n  labs(x = \"HOLC Grades\",\n       y = \"Percentile of PM 2.5 Concentrations\") +\n  theme_minimal()\n\n\nlow_life &lt;- ggplot(sum_stats, aes(grade,P_LIFEEXPPCT, fill = grade))+\n  geom_boxplot(show.legend = FALSE) +\n  stat_summary(fun =mean, geom =\"point\", shape=20, size=6, color=\"pink\", fill=\"pink\") +\n    theme(legend.position=\"none\") +\n    scale_fill_brewer(palette=\"Set1\") +\n  labs(x = \"HOLC Grades\",\n       y = \"Percentile of Low Life Expectancy\") +\n  theme_minimal()\n\n# View patchworked plots\nprint(low_inc + PM_p + low_life)\n\n\n\n\n\n\n\n\n\nThe results of the figures is not surprising, it follows a pattern in each plot. In all cases we see here, the D grade HOLC areas have the highest values, meaning that they have the highest percentage of low income, the highest percentage of low life expectancy, and the highest percentile of PM 2.5 concentrations. As the grades go up, the low income, PM concentrations, and low life expectancy goes down.\nUnfortunately, it’s still clear to see how redlined districts continue to impact quality of life in low graded neighborhoods. We can also see the effects of redlining through biodiversity disparities. We will introduce data on bird observations in LA, and then examine whether there is a pattern between observations and HOLC grades."
  },
  {
    "objectID": "posts/EJ_LA/index.html#part-2-legacy-of-redlining-in-biodiversity-observations",
    "href": "posts/EJ_LA/index.html#part-2-legacy-of-redlining-in-biodiversity-observations",
    "title": "Environmental Justice and Biodiversity",
    "section": "Part 2: Legacy of redlining in biodiversity observations",
    "text": "Part 2: Legacy of redlining in biodiversity observations\n\n# Check coordinate reference system\nprint(st_crs(birds) == st_crs(holc_transform))\n\n[1] FALSE\n\n# Change coordinate system for birds to match holc_transform\nbirds_transform &lt;- st_transform(birds, crs = st_crs(holc_transform))\n\n# Check that it works\nif(st_crs(birds_transform) == st_crs(LA)){\n  print(\"it's a match!\")\n} else {\n  warning(\"not a match, check your coordinate systems!\")\n}\n\n[1] \"it's a match!\"\n\n# filter to 2022\nbirds_2022 &lt;- birds_transform |&gt;\n  filter(year == 2022)\n\n# check that years are correct\nexpect_true(unique(birds_2022$year) == 2022)\n\n\n# Join bird data into HOLC data\nbird_redline &lt;- st_join(holc_transform, birds_2022, join = st_intersects)\n\n# Group birds by grades\ngrade_bird &lt;- bird_redline |&gt; \n  st_drop_geometry() |&gt;\n  group_by(grade) |&gt;\n  summarize(obs_percent = n()/nrow(bird_redline)*100)\n\n# Recalculate by area\narea_holc_bird &lt;- bird_redline |&gt;\n  group_by(grade) |&gt;\n  summarize(total_area = sum(area, na.rm = TRUE),\n            grade_count = n()) |&gt;\n  mutate(bird_count_area = grade_count/total_area) |&gt;\n  select(grade, bird_count_area) |&gt;\n  st_drop_geometry()\n\n\n\nCode\n# Create plot\npercent_plot &lt;- ggplot(grade_bird) +\n  geom_col(aes(x = grade, y = obs_percent, fill = grade), show.legend = FALSE) +\n  labs(x = \"Grades\",\n       y = \"Percent of Bird Observations\",\n       title = \"Percent of Bird Observations\\n in HOLC Grades\",\n       caption = \"     * this graph does not take\\n into account varying HOLC area sizes\")\n\n# Create plot\narea_plot &lt;- ggplot(area_holc_bird) +\n  geom_col(aes(x = grade, y = bird_count_area, fill = grade), show.legend = TRUE) +\n  labs(x = \"Grades\",\n       y = \"Bird Observations by area\",\n       title = \"Bird Observations by Area Size\\n of HOLC Grades\")\n\n# View plots\nprint(percent_plot + area_plot)\n\n\n\n\n\n\n\n\n\nAt first glance, it looks like the percent of bird observations in HOLC graded areas are counter intuitive. It looks as if C and D have the highest percentage of bird observations, which goes completely against what we would expect. Ellis-Soto et all writes that historically redlined districts are under sampled in terms of bird diversity. Why is our data different? When looking at the map of HOLC grades, the answer is clear, there is significantly more areas with A and B grades. This means that although there are more bird observations in A and B areas, their percentages are lower because they cover more area. To look at how the bird observations actually change by grade, we recalculated the bird data to account for the size of the HOLC graded areas. When looking at the second figure, it lines up with Ellis-Soto et al. Although the pattern is not perfect, the D grade does have the lowest observations by far.\nThis project only begins to touch on the environmental and socioeconomic lasting impacts of redlining in LA and over the entirety of the US. This project was led by Dr. Ruth Oliver in a graduate level Geospatial Analysis class at the Bren School for Environmental Science and Management at UCSB.\n\nCitation\n\n\n\n\n\n\n\n\nData\nCitation\nLink\n\n\n\n\nEJ Screen Data\nEPA. EJScreen Tool.\nhttps://www.epa.gov/ejscreen/download-ejscreen-data\n\n\nHOLC Redlining Data\nDigital Scholarship Lab. Mapping Inequality Project\nhttps://dsl.richmond.edu/panorama/redlining/data\n\n\nBiodiversity Observation Data\nGlobal Biodiversity Information Facility\nhttps://eds-223-geospatial.github.io/assignments/gbif.org\n\n\nHistorical Redlining Paper\nEllis-Soto D, Chapman M, Locke DH. Historical redlining is associated with increasing geographical disparities in bird biodiversity sampling in the United States. Nat Hum Behav. 2023 Nov;7(11):1869-1877. doi: 10.1038/s41562-023-01688-5. Epub 2023 Sep 7. PMID: 37679441.\nhttps://pubmed.ncbi.nlm.nih.gov/37679441/"
  },
  {
    "objectID": "posts/Natural_resource_corruption/index.html",
    "href": "posts/Natural_resource_corruption/index.html",
    "title": "Natural Resource Wealth and Corruption",
    "section": "",
    "text": "Corruption is an issue in countries across the world. Government structures are complicated, intertwined, and often run behind closed doors. This makes it extremely difficult to solve. What are the main influences on a country’s corruption level? Is it even quantifiable? I was motivated by these questions to take a stab at a small piece of the corruption puzzle.\nIn this post we attempt to answer the question does the percent of GDP from natural resources affect countries’ corruption levels?\nMy theory is that having natural resources that provide a large revenue source for a country could potentially invite corruption. Public officials may bribe gas, oil, or logging companies for a cut in the profit. Those companies may also bribe or attempt to coerce the government into larger sales or more land. Public officials may also prioritize company profits over public welfare, which has the potential to have large impacts on policy decisions that affect citizens.\nThe theory that I am describing is a very simplified version of a well-studied and highly debated issue of the resource curse. Essentially natural resource wealth in countries (specifically developing countries) can lead to perverse effects on economic, social, and political well being. Case studies around the world have proved this to be true (although there is also case study evidence of the resource curse being “illusory”).\nEveryone wants to solve corruption, but it’s a lot easier said than done. Corruption is a complicated issue with far more influences than most researchers are able to analyze in years of study, and certainly more than I can analyze in this short post.\nMy analysis plan is to create visualizations and linear models that can help us to examine the possibility of a significant correlation between the percent of GDP in a country that comes from natural resources versus our corruption perception index."
  },
  {
    "objectID": "posts/Natural_resource_corruption/index.html#sources",
    "href": "posts/Natural_resource_corruption/index.html#sources",
    "title": "Natural Resource Wealth and Corruption",
    "section": "Sources",
    "text": "Sources\n\nCorruption Perception Index\n\nOur data comes from two different sources. The first source is for our corruption level data. We used a dataset from Transparency International, an organization that works to fight corruption worldwide. The organization has many facets, including a think tank, a UNESCO consultant, and is involved in the UN.\nThey created a corruption perceptions index, which measures levels of corruption in 180 countries around the world from 0 (highly corrupt) to 100 (very clean). Transparency International takes data from 13 sources, such as banks, think tanks, and research advisory firms around the world. Each of these organizations ask leading experts in their field multiple questions that can be used to gage corruption levels. Some sources only cover specific regions or continents, while others cover the majority of the world. Transparency International then takes the information and standardizes it on a scale of zero to one hundred,“this standardisation is done by subtracting the mean of each source in the baseline year from each country score and then dividing by the standard deviation of that source in the baseline year [and]… …transformed to the CPI scale by multiplying with the value of the CPI standard deviation in 2012 (20) and adding the mean of CPI in 2012 (45), so that the data set fits the CPI’s 0-100 scale” (CPI report short methodology 2021). They then calculate the average for each country to find their published score.\n\nLimitations of the data\nThe data itself, as well as the way I use it comes with some caveats. Firstly, Transparency International uses varying organizations to get these scores, which in turn use varying methods to get their scores. Although the scores are then standardized, it is still not a completely equal comparison for every single country. In my statistical analysis, I use this corruption perception index as a true corruption index for each country. There are clearly limitations to what anyone can truly know about the country in their country, and this index simply measures perceptions for that very reason, but for the purposes of my calculations I treat these numbers as true and fair values. In order to simplify my analysis, I am also not including the standard errors for these values, which could potentially oversimplify the results of the index.\nTransparency International. (2021). 2021 Corruptions Perceptions Index. Transparency.org. https://www.transparency.org/en/cpi/2021.\n\n\n\nPercent of GDP from Natural Resources\nThe natural resource data comes from the World Bank Group, an organization with 189 member countries, working to give funds to low income countries. Their site also has a catalog of open data about economic development worldwide. The dataset we used was the “World Development Indicators: Contribution of natural resources to gross domestic product” table. I have used data from 2021 in order to have consistency in the year across the board.\n\nLimitations of the data\nAlthough this data is open source, we have no information about how these numbers were acquired. We trust at face value that this dataset is correct.\nWorld Development Indicators. The World Bank. (2015). Worldbank.org. https://wdi.worldbank.org/table/3.14#\n\n\n\nSet up:\n\n\nCode\n# read in libraries\nlibrary(tidyverse)\nlibrary(here)\nlibrary(readr)\nlibrary(janitor)\nlibrary(sjPlot)\nlibrary(spdep)\n\n\n\n\nCode\n# read in data\ncorruption &lt;- read_csv(here(\"posts\", \"Natural_resource_corruption\" ,\"data\", \"2021_corruption.csv\"))\n\nnatural_resources &lt;- read_csv(here(\"posts\", \"Natural_resource_corruption\" ,\"data\", \"natural_resources.csv\"))\n\n\n\n\nClean up the data\nOur data comes from multiple sources. In order to join the corruption and natural resources datasets together, it’s crucial that we make sure that all the information is clean and lines up.\n\n\nCode\n# Take our the rows that doesn't contain data from countries\nnatural_resources &lt;- natural_resources[1:217, ]\n\n# Join the data together\ncorrupt_resource &lt;- full_join(corruption, natural_resources, by = c(\"Country / Territory\" = \"Country\"))\n\n# Rename the country column for clarity and clean up names\ncorrupt_resource_clean &lt;- corrupt_resource |&gt; \n  rename(\"country\" = \"Country / Territory\") |&gt; \n  clean_names() \n\n# Select the columns we're interested in\ncorrupt_resource_select &lt;- corrupt_resource_clean |&gt; \n  select(country, iso3, cpi_score_2021,total_natural_resources_rents_percent_of_gdp, oil_rents_percent_of_gdp, natural_gas_rents_percent_of_gdp, coal_rents_percent_of_gdp, mineral_rents_percent_of_gdp, forest_rents_percent_of_gdp)\n\n# Change CPI score data to numeric so we can work with it\ncorrupt_resource_select$cpi_score_2021 &lt;- as.numeric(corrupt_resource_select$cpi_score_2021)\n\n# Change total natural resource data to numeric as well\ncorrupt_resource_select$total_natural_resources_rents_percent_of_gdp &lt;- as.numeric(corrupt_resource_select$total_natural_resources_rents_percent_of_gdp)\n## Warning: NAs introduced by coercion\n\n# exclude outliers\ncorrupt_resource_select &lt;- corrupt_resource_select |&gt; \n  filter(total_natural_resources_rents_percent_of_gdp &lt;= 40) |&gt; \n  filter(!is.na(cpi_score_2021))\n\n\n\n\nMake a preliminary plot\n\n\nCode\n# Plot the data\nfirst_plot &lt;- ggplot(corrupt_resource_select, aes(x=total_natural_resources_rents_percent_of_gdp, y = cpi_score_2021)) +\n  geom_point() +\n  xlab(\"percent of GDP from natural resources\") +\n  ylab(\"corruption perception index\") +\n  labs(title = \"Natural Resource's affect on countries' corruption levels\") +\n  theme_grey() \n\nprint(first_plot)\n\n\n\n\n\n\n\n\n\nAt first glance, our data doesn’t really look correlated at all. But let’s dive a little deeper.\n\n# Run linear regression summary\nlm1 &lt;- lm(cpi_score_2021 ~ total_natural_resources_rents_percent_of_gdp, data = corrupt_resource_select)\n\ntab_model(lm1)\n\n\n\n\n\n\n\n\n\n\n \ncpi score 2021\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n48.35\n44.82 – 51.88\n&lt;0.001\n\n\ntotal natural resources\nrents percent of gdp\n-0.54\n-0.86 – -0.23\n0.001\n\n\nObservations\n153\n\n\nR2 / R2 adjusted\n0.072 / 0.066\n\n\n\n\n\n\n\nThere are a few numbers here that are of interest to us. First let’s look at the intercept and the total_natural_resources_rents_percent_of_gdp (the slope). According to our model, if our hypothetical country had no GDP resulting from natural resources, then the corruption level would be at 48. We could maybe buy this if we hadn’t looked at the graph, but when we look at our data points visually it looks like our intercept is really just halfway in between our huge cluster of points around zero that seem to be evenly dispersed on the y axis. When looking at the slope we can also see that it’s very small. Each percentage point increase in GDP results in a less than 1 index level decrease.\nThe p-values for both our intercept and slope are very small. Our intercept is less than .001 (essentially zero for our purposes) and our slope has a p-value of .000106, also a very small number. Both are far below .05, the number needed for a value to be statistically significant. So if these values are both statistically significant, why do I still not trust that it’s meaningful?\nLet’s look at adjusted R squared value. It’s about 0.07. R squared is always a value from 0 to 1, where 0 means that the model explains essentially zero percent of the change in y, and 1 means that the model is the perfect fit and the variable explains 100 percent of the change in y. Our value is less than .1, essentially meaning that the percent of GDP from natural resources explains just over 7 percent of the corruption levels in countries. So our model is statistically significant but explains very little of corruption levels.\nThis makes sense when we look at our graph with our best fit line. If we squint at the graph, we can maybe see a correlation, but it’s certainly a stretch. The graph, along with our linear model summary, makes us think that there is definitely omitted variable bias here.\n\n\nCode\nsmooth_plot &lt;- ggplot(corrupt_resource_select, aes(x=total_natural_resources_rents_percent_of_gdp, y = cpi_score_2021)) +\n  geom_point() +\n  xlab(\"percent of GDP from natural resources\") +\n  ylab(\"corruption perception index\") +\n  labs(title = \"Natural Resource's affect on countries' corruption levels\") +\n  theme_grey() +\ngeom_smooth(formula = y ~ x,\n              se = FALSE,\n              method = lm)\nprint(smooth_plot)\n\n\n\n\n\n\n\n\n\n\n\nLet’s regroup and think about what other variables could be contributing to corruption levels.\nMy new theory is that the type of government could be a major contributing factor in corruption levels. It’s possible that this is an interactive model. My theory is that democratic countries will have a much less steep negative slope because the percent of GDP from natural resources would have less of an effect on corruption. Elections keep officials much more accountable. On the other hand, autocracies might have a steeper negative slope, as more money coming from a country’s natural resource could lead to an increase in corruption as there is more money or resources that could be exploited. Let’s load in another dataset that has information on political regimes worldwide and test my theory.\nMy new analysis plan is to add political regime type to my model as an interaction. We can then graph and analyze the data to see if there’s a correlation now that political regime type is added.\n\nread in data and clean\nmake interactive plot\nrun a linear model\nanalyze results\n\n\nAbout this data\nOur data comes from Our World in Data, a website dedicated to being an open source platform for data sets to be used by scientists and others to improve our world. The website is slowly funded by grants and donations, and is made to be a platform for all.\nOur specific data “Political Regime, 2021”, is a dataset of countries worldwide. They all get a designation of 0 through 3, which the political regime.\n\n0 represents closed autocracies, where “citizens do not have the right to either choose the chief executive of the government or the legislature through multi-party elections”\n1 represents electoral autocracies, where “citizens have the right to choose the chief executive and the legislature through multi-party elections; but they lack some freedoms, such as the freedoms of association or expression, that make the elections meaningful, free, and fair”\n2 represents electoral democracies, where ” citizens have the right to participate in meaningful, free and fair, and multi-party elections”\n3 represents liberal democracies, where “citizens have further individual and minority rights, are equal before the law, and the actions of the executive are constrained by the legislative and the courts”\n\n(all descriptions come from the dataset’s metadata) For clarity, I clean the data to change the numbers to the regime type\nThe data comes from the Regimes of the World (RoW) data published by the Varieties of Democracy (V-Dem) project. Political scientists Anna Lührmann, Marcus Tannenberg, and Staffan Lindberg compiled assessments from anonymous experts in academia, media, or civil society to gage democracy levels.\n\n\nLimitations to our data\nDemocracy levels are mainly subjective. Although the data is as standardized as possible, subjectivity is impossible to avoid. People may have different ideas of civil freedoms or the voting in their country. The datasheet about the data does acknowledge this, although it’s impossible to completely fix. For our purposes here, I have chosen to take their political regime designations as objective truth.\nPolitical regime. (n.d.). Our World in Data. https://ourworldindata.org/grapher/political-regime?time=2021\nHerre, B. (2021, December 2). The “Regimes of the World” data: how do researchers identify which countries are democracies? Our World in Data. https://ourworldindata.org/regimes-of-the-world-data\n\n\nCode\n# Read in data\nregime &lt;- read_csv(here(\"posts\", \"Natural_resource_corruption\", \"data\", \"political-regime.csv\"))\n\n\n\n\nCode\n# Clean column names\nregime_clean &lt;- regime |&gt; \n  rename(\"country\" = \"Entity\") |&gt; \n  clean_names() \n\n# Replace numeric values with descriptive labels\nregime_clean &lt;- regime_clean %&gt;%\n  mutate(political_regime = case_when(\n    political_regime == 0 ~ \"closed_autocracies\",\n    political_regime == 1 ~ \"electoral_autocracies\",\n    political_regime == 2 ~ \"electoral_democracies\",\n    political_regime == 3 ~ \"liberal_democracies\"\n  ))\n\n\n\n\nCode\n# Join with other dataframe\ncorrupt_nat_dem &lt;- full_join(corrupt_resource_select, regime_clean, by = c(\"iso3\" = \"code\"))\n\n# Select only rows and columns we're interested in\ncorrupt_nat_dem_select &lt;- corrupt_nat_dem[1:180, ] |&gt; \n  select(-country.y, -time, -year)\n\n\n\n\nCode\nregime_plot &lt;- ggplot(corrupt_nat_dem_select, aes(x = total_natural_resources_rents_percent_of_gdp, y = cpi_score_2021, color = political_regime)) +\n  geom_point() +\n   xlab(\"percent of GDP from natural resources\") +\n  ylab(\"corruption perception index\") +\n  labs(title = \"Natural Resource's affect on countries' corruption levels\",\n       color = \"Political regime\") +\n  theme_grey() +\n  geom_smooth(formula = y ~ x,\n              se = FALSE,\n              method = lm) +\n  scale_color_hue(labels = c(\"closed autocracies\", \"electorial autocracies\", \"electoral democracies\", \"liberal democracies\"))\n\nprint(regime_plot)\n## Warning: Removed 27 rows containing non-finite outside the scale range\n## (`stat_smooth()`).\n## Warning: Removed 27 rows containing missing values or values outside the scale range\n## (`geom_point()`).\n\n\n\n\n\n\n\n\n\nNow this isn’t the prettiest graph, but it’s good enough that we can see the lines of best fits by regime type and we can see where the actual data points fall to get an idea of the accuracy of our best fit line.\nWe can see that the liberal democracies line is actually positive, which means that the as natural resource profit goes up, they have less and less corruption. Interestingly, electoral democracies and electoral autocracies seem to have very similar negative slopes. The closed autocracies seem to have a mostly flat slope that it very slightly positive.\nThese results are pretty unexpected. Let’s take a look at the linear model summary to check out our numbers.\n\nlm2 &lt;- lm(total_natural_resources_rents_percent_of_gdp ~ cpi_score_2021 + political_regime +cpi_score_2021:political_regime, data = corrupt_nat_dem_select)\n\ntab_model(lm2)\n\n\n\n\n\n\n\n\n\n\n \ntotal natural resources\nrents percent of gdp\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n1.75\n-8.05 – 11.54\n0.725\n\n\ncpi score 2021\n0.24\n-0.00 – 0.49\n0.054\n\n\npolitical regime\n[electoral_autocracies]\n12.22\n-0.02 – 24.47\n0.050\n\n\npolitical regime\n[electoral_democracies]\n12.21\n-2.05 – 26.48\n0.093\n\n\npolitical regime\n[liberal_democracies]\n-1.74\n-24.48 – 21.00\n0.880\n\n\ncpi score 2021 ×\npolitical regime\n[electoral_autocracies]\n-0.38\n-0.70 – -0.05\n0.023\n\n\ncpi score 2021 ×\npolitical regime\n[electoral_democracies]\n-0.43\n-0.77 – -0.08\n0.016\n\n\ncpi score 2021 ×\npolitical regime\n[liberal_democracies]\n-0.22\n-0.59 – 0.16\n0.258\n\n\nObservations\n150\n\n\nR2 / R2 adjusted\n0.158 / 0.116\n\n\n\n\n\n\n\nThe first thing I notice when I look at our results are that most p-values are above .05, which makes them all statistically insignificant. Therefore we fail to reject the null hypothesis. The only one that is significant is the electoral autocracies, although because the other values are not statistically significant, it’s hard for me to trust the electoral autocracy coefficients independent of the other values. It makes sense to me that this interaction is insignificant, because the slopes we were getting were very surprising and didn’t make much logical sense to me. We cannot assume that any of the interaction trends we saw were not just due to chance.\n\n\n\nMoran’s I\nIt seems like adding in the political regime was not the omitted variable I was looking for. I’m starting to suspect that there may be some spatial clumping and autocorrelation going on here. Let’s perform the Moran’s I test and plot the results to test my new hypothesis.\n\n\nCode\n# Use the world dataset included in the spData library\nworld &lt;- spData::world\n\n# Join world dataset with previous data\nworld_join &lt;- full_join(corrupt_resource_select, world, by = c(\"country\" = \"name_long\")) \n\n# Filter dataset to remove all NAs in relevant columns\nworld_join &lt;- world_join |&gt; \n  filter(!is.na(geom)) |&gt;\n  filter(!is.na(pop)) \nworld_join &lt;- world_join[1:135,]\n\n# Assign name to linear model\nworld_lm &lt;- lm(cpi_score_2021 ~ total_natural_resources_rents_percent_of_gdp, data = world_join)\n\n# Assign residual column\nworld_join$residual &lt;- resid(world_lm)\n\n# Make into sf object\nworld_join &lt;- st_as_sf(world_join, \n                        crs = \"EPSG:4326\",\n                       sf_column_name = 'geom')\n\n# Make into centroids\npts &lt;- st_centroid(st_transform(world_join, 4326)) \npts &lt;- pts |&gt; \n  filter(!is.na(pop)) |&gt; \n  filter(!is.na(geom))\n\n# Find neighbors\nworld_join.nb &lt;- dnearneigh(pts, d1 = 0, d2 = 5000)\n\n# Add spatiral weights\nworld_join.lw &lt;- nb2listw(world_join.nb, style = \"W\", zero.policy = TRUE)\n\n# Perform Moran's I test\nmoran_test &lt;- moran.test(world_join$residual, world_join.lw, zero.policy = TRUE)\n\n# Print the Moran's I test results\nprint(moran_test)\n## \n##  Moran I test under randomisation\n## \n## data:  world_join$residual  \n## weights: world_join.lw    \n## \n## Moran I statistic standard deviate = 6.8527, p-value = 3.624e-12\n## alternative hypothesis: greater\n## sample estimates:\n## Moran I statistic       Expectation          Variance \n##      0.1284541112     -0.0074626866      0.0003933933\n\n# Plot results\nmorans_plots &lt;- ggplot() + \n  geom_sf(data = world, fill = \"lightgray\", color = \"darkgray\") +\n  geom_sf(data = world_join, aes(fill = residual, geometry = geom)) + scale_fill_gradient(low = \"darkblue\", high = \"red\") +\n  labs( title = \"Moran's I\",\n         x = \"Longitude\", \n         y = \"Latitude\" ) + \n  theme_minimal()\n\nprint(morans_plots)\n\n\n\n\n\n\n\n\n\nUnfortunately, we had to omit a good amount of countries because all of our datasets did not match. Despite this, we can still see a pattern of autocorrelation in our data. We can see in Northern Europe and in the Middle East, there is almost a gradient of colors because of autocorrelation. Countries close to red countries seem to be closer to red themselves, while countries close to blue countries seem to be closer to blue themselves. Similar colors are also clumped together in South American and Africa. This tells us that one country’s corruption levels are affecting others around it."
  },
  {
    "objectID": "posts/Natural_resource_corruption/index.html#summarizing-our-results",
    "href": "posts/Natural_resource_corruption/index.html#summarizing-our-results",
    "title": "Natural Resource Wealth and Corruption",
    "section": "Summarizing our results",
    "text": "Summarizing our results\nOur results are overall inconclusive. Our first linear model just looked at the percent of GDP from natural resources. There was no an obvious correlation from just looking at the data points on the graph, but our line of best fit revealed a negative slope, revealing that as the percent of GDP goes up, the corruption also goes up (a lower index number = more corruption). Although these results were statistically significant, the adjusted R squared value revealed that it only explained about nine percent of the corruption levels in countries around the world.\nMy solution to the low R squared value was to add another variable, as it was quite likely we had omitted variable bias. I decided to add political regime type as our additional variable. I logically assumed that the regime type would have differing affects on the relationship. When I added in political regimes however, I saw that my results were no longer statistically significant.\nIn an effort to explore what else could be contributing to corruption levels, I decided to try the Moran’s I test, which allows us to see if there is autocorrelation in our data. The answer was yes, there appears to be some. That means that countries’ corruption levels are being affected by the levels around it. Maybe stability in the surrounding countries bring stability into their neighbors’ countries. Maybe corruption spills over across borders. If we think about natural resources as well, they don’t follow political lines. Natural resources will probably be similar in neighboring countries. All of these factors lead to a need to examine further and account for this autocorrelation in our analysis.\nIf I had more time I would have continued exploring more variables and use our results from Moran’s I to account for our autocorrelation issue. Developed versus developing country, overall GDP amount, and economic systems would all be interesting to analyze in relation to corruption and natural resources as well. I am also skeptical that a linear model is truly the correct model to be using in this situation, as corruption is very complex and probably not a completely linear issue.\nMy next steps would be to use my Moran’s I calculations to go back and reanalyze my data, as well as add in additional factors that I believe could be relevant.\nFull acknowledgements:\n\n\n\n\n\n\n\nUse:\nCitation:\n\n\n\n\nResource curse information\nRoss, M. L. (2013). The Politics of the Resource Curse: A Review. SSRN Electronic Journal. https://doi.org/10.2139/ssrn.2342668\n\n\nNatural resources data\nWorld Development Indicators. The World Bank. (2015). Worldbank.org. https://wdi.worldbank.org/table/3.14#\n\n\nCorruption index data\nTransparency International. (2021). 2021 Corruptions Perceptions Index. Transparency.org. https://www.transparency.org/en/cpi/2021.\n\n\nPolitical regime data\nPolitical regime. (n.d.). Our World in Data. https://ourworldindata.org/grapher/political-regime?time=2021\n\n\nPolitical regime metadata\nHerre, B. (2021, December 2). The “Regimes of the World” data: how do researchers identify which countries are democracies? Our World in Data. https://ourworldindata.org/regimes-of-the-world-data\n\n\nReference course materials\nMax Czapanskiy. EDS 222 Statistics for Environmental Data Science graduate course at the Bren School of Environmental Science and Management at UCSB"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "How Fish and Other Marine Species Change Throughout the San Francisco Estuary\n\n\n\nR\n\n\nMEDS\n\n\n\nThe design process and elements behind the infographic\n\n\n\nEmma Bea Mitchell\n\n\nMar 16, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnvironmental Justice and Biodiversity\n\n\n\nGeospatial\n\n\nR\n\n\nMEDS\n\n\n\nExploring patterns of historic redlining and bird diversity\n\n\n\nEmma Bea Mitchell\n\n\nJan 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNatural Resource Wealth and Corruption\n\n\n\nStats\n\n\nR\n\n\nMEDS\n\n\n\nA first stab at statistically analyzing the resource curse\n\n\n\nEmma Bea Mitchell\n\n\nDec 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImpacts of the Thomas Fire\n\n\n\nPython\n\n\nMEDS\n\n\n\nVisualizing AQI and fire scars with plots and false color imagery\n\n\n\nEmma Bea Mitchell\n\n\nDec 4, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  }
]